{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUhT9Sq+rt3W3bMzTFE3ud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivekDubey18/Digit_Recognizing_using_Tensorflow/blob/main/Digit_Recognizing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-JegGl7TXAC"
      },
      "outputs": [],
      "source": [
        "# TensorFlow/Keras version\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Normalize input images i.e range is converted [0-255] --> [0-1] to improve performance and stability\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "#Converts the integer labels e.g. 3-> into  --> one-hot vectors  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) to work efficiently with categorical_crossentropy\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),   # Conv Layer 1  (1st layer after input layer)\n",
        "    MaxPooling2D(pool_size=(2, 2)),                                   # Max Pooling\n",
        "    Conv2D(64, (3, 3), activation='relu'),                            # Conv Layer 2\n",
        "    MaxPooling2D(pool_size=(2, 2)),                                   # Max Pooling\n",
        "    Flatten(),                                                        # Flatten to 1D\n",
        "    Dense(128, activation='relu'),                                    # Fully connected layer  (total dense layer = 1 that contain 128 neurons)\n",
        "    Dropout(0.5),                                                     # Dropout for regularization\n",
        "    Dense(10, activation='softmax')                                   # Output Layer (10 nerons for 10 classes 0-9)\n",
        "])\n"
      ],
      "metadata": {
        "id": "aEZs45ssTYI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',       # to calculate loss function\n",
        "              metrics=['accuracy'])                  # to calculate accuracy\n",
        "\n",
        "\n",
        "\n",
        "#Define callbacks\n",
        "#it saves the best performing model ignoring the model where accuracy decreases\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5', monitor='val_accuracy', save_best_only=True,\n",
        "    mode='max', verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "#to handle overfitting it monitor validation_loss ....ans if validation loss continues for 3 epochs it will terminate and saves the model where the best weights are present\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss', patience=3, restore_best_weights=True, verbose=1\n",
        ")\n",
        "\n",
        "#Train the model with callbacks\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=8,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[checkpoint, early_stop]"
      ],
      "metadata": {
        "id": "nqNlWPuaXn0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training & validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy : {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "O-CagXcKeHBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}