
---

## ğŸ“Š Dataset
- **Source**: [MNIST Handwritten Digit Dataset](http://yann.lecun.com/exdb/mnist/)
- **Size**: 60,000 training images, 10,000 test images
- **Image Size**: 28Ã—28 pixels, grayscale

---

## âš™ï¸ Model Architecture
1. **Conv2D (32 filters, 3Ã—3, ReLU)**  
2. **MaxPooling2D (2Ã—2)**  
3. **Conv2D (64 filters, 3Ã—3, ReLU)**  
4. **MaxPooling2D (2Ã—2)**  
5. **Flatten Layer**  
6. **Dense (128 neurons, ReLU)**  
7. **Dropout (0.5)**  
8. **Dense (10 neurons, Softmax)**  

---

## ğŸš€ Training Details
- **Optimizer**: Adam  
- **Loss Function**: Categorical Crossentropy  
- **Batch Size**: 32  
- **Epochs**: 8 (with Early Stopping)  
- **Validation Split**: 10%  

---

## ğŸ“Œ Callbacks Used
- **ModelCheckpoint** â†’ Saves the best model based on validation accuracy.  
- **EarlyStopping** â†’ Stops training if validation loss doesn't improve for 3 consecutive epochs.  

---

## ğŸ“ˆ Results

**Training vs Validation Accuracy**
![Accuracy Plot](result.png)

**Final Test Accuracy:** ~98% âœ…



1. **Clone the repository**
```bash
git clone https://github.com/yourusername/mnist-cnn.git
cd mnist-cnn
